satvik@nid001004:/pscratch/sd/s/satvik/CSC-746/cp5/scripts> ./skeleton-gpu-batch-script.sh
Running with 32 threads per block and 1 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806269 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1 blocks, 32 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806269
[806269] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.02
    gpu__time_duration.avg                                    msecond       977.30
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.23
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          1.22
    SM Frequency            cycle/nsecond          1.10
    Elapsed Cycles                  cycle 1,070,156,582
    Memory Throughput                   %          0.03
    DRAM Throughput                     %          0.02
    Duration                      msecond        977.30
    L1/TEX Cache Throughput             %          3.01
    L2 Cache Throughput                 %          0.02
    SM Active Cycles                cycle  9,908,503.28
    Compute (SM) Throughput             %          0.03
    ----------------------- ------------- -------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread              32
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp            1
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,128
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 32 threads per block and 4 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806591 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4 blocks, 32 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806591
[806591] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.06
    gpu__time_duration.avg                                    msecond       284.57
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.93
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          1.22
    SM Frequency            cycle/nsecond          1.10
    Elapsed Cycles                  cycle   311,625,720
    Memory Throughput                   %          0.11
    DRAM Throughput                     %          0.06
    Duration                      msecond        284.57
    L1/TEX Cache Throughput             %          2.87
    L2 Cache Throughput                 %          0.09
    SM Active Cycles                cycle 11,541,254.19
    Compute (SM) Throughput             %          0.11
    ----------------------- ------------- -------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             128
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp         1.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,134
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 32 threads per block and 16 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806702 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 16 blocks, 32 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806702
[806702] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (16, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.24
    gpu__time_duration.avg                                    msecond        75.14
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.70
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          1.21
    SM Frequency            cycle/nsecond          1.09
    Elapsed Cycles                  cycle    82,269,082
    Memory Throughput                   %          0.37
    DRAM Throughput                     %          0.24
    Duration                      msecond         75.14
    L1/TEX Cache Throughput             %          2.48
    L2 Cache Throughput                 %          0.35
    SM Active Cycles                cycle 12,181,532.71
    Compute (SM) Throughput             %          0.43
    ----------------------- ------------- -------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             512
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp         1.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.87%
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,158
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 32 threads per block and 64 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806770 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 64 blocks, 32 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806770
[806770] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (64, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.95
    gpu__time_duration.avg                                    msecond        19.06
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        14.80
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          1.21
    SM Frequency            cycle/nsecond          1.09
    Elapsed Cycles                  cycle    20,864,229
    Memory Throughput                   %          1.45
    DRAM Throughput                     %          0.95
    Duration                      msecond         19.06
    L1/TEX Cache Throughput             %          2.45
    L2 Cache Throughput                 %          1.36
    SM Active Cycles                cycle 12,350,819.65
    Compute (SM) Throughput             %          1.69
    ----------------------- ------------- -------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,048
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp         1.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,254
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 32 threads per block and 256 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806816 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 256 blocks, 32 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806816
[806816] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (256, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         3.47
    gpu__time_duration.avg                                    msecond         5.21
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        59.22
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    5,713,639
    Memory Throughput                   %         5.31
    DRAM Throughput                     %         3.47
    Duration                      msecond         5.21
    L1/TEX Cache Throughput             %         5.32
    L2 Cache Throughput                 %         4.87
    SM Active Cycles                cycle 5,706,172.44
    Compute (SM) Throughput             %         6.16
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         3.70
    Achieved Active Warps Per SM           warp         2.37
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 92.59%
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference
          between calculated theoretical (50.0%) and measured achieved occupancy (3.7%) can be the result of warp
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,638
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 32 threads per block and 1024 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806883 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1024 blocks, 32 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806883
[806883] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1024, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        10.82
    gpu__time_duration.avg                                    msecond         1.68
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        99.47
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    1,829,799
    Memory Throughput                   %        17.05
    DRAM Throughput                     %        10.82
    Duration                      msecond         1.68
    L1/TEX Cache Throughput             %        17.12
    L2 Cache Throughput                 %        14.28
    SM Active Cycles                cycle 1,821,826.06
    Compute (SM) Throughput             %        19.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          32,768
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        14.77
    Achieved Active Warps Per SM           warp         9.45
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 70.46%
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference
          between calculated theoretical (50.0%) and measured achieved occupancy (14.8%) can be the result of warp
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,727,174
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 32 threads per block and 4096 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806929 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4096 blocks, 32 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806929
[806929] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4096, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        21.57
    gpu__time_duration.avg                                    usecond       943.71
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        98.22
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    1,031,817
    Memory Throughput                   %        30.23
    DRAM Throughput                     %        21.57
    Duration                      usecond       943.71
    L1/TEX Cache Throughput             %        30.48
    L2 Cache Throughput                 %        27.67
    SM Active Cycles                cycle 1,023,477.85
    Compute (SM) Throughput             %        34.15
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         131,072
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 50%
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 639 thread blocks.
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for
          up to 50.0% of the total kernel runtime with a lower occupancy of 34.5%. Try launching a grid with no
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for
          a grid. See the Hardware Model
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more
          details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        32.74
    Achieved Active Warps Per SM           warp        20.96
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 34.51%
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference
          between calculated theoretical (50.0%) and measured achieved occupancy (32.7%) can be the result of warp
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,733,318
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 64 threads per block and 1 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 806975 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1 blocks, 64 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 806975
[806975] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.04
    gpu__time_duration.avg                                    msecond       492.98
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.46
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle  539,819,757
    Memory Throughput                   %         0.06
    DRAM Throughput                     %         0.04
    Duration                      msecond       492.98
    L1/TEX Cache Throughput             %         5.98
    L2 Cache Throughput                 %         0.03
    SM Active Cycles                cycle 4,998,140.35
    Compute (SM) Throughput             %         0.07
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread              64
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,130
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 64 threads per block and 4 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808095 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4 blocks, 64 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808095
[808095] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.12
    gpu__time_duration.avg                                    msecond       155.10
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         1.85
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle  170,177,715
    Memory Throughput                   %         0.20
    DRAM Throughput                     %         0.12
    Duration                      msecond       155.10
    L1/TEX Cache Throughput             %         5.41
    L2 Cache Throughput                 %         0.17
    SM Active Cycles                cycle 6,311,594.64
    Compute (SM) Throughput             %         0.21
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             256
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,142
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 64 threads per block and 16 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808189 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 16 blocks, 64 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808189
[808189] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (16, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.44
    gpu__time_duration.avg                                    msecond        40.99
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         7.40
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.23
    SM Frequency            cycle/nsecond         1.11
    Elapsed Cycles                  cycle   45,420,432
    Memory Throughput                   %         0.75
    DRAM Throughput                     %         0.44
    Duration                      msecond        40.99
    L1/TEX Cache Throughput             %         5.07
    L2 Cache Throughput                 %         0.61
    SM Active Cycles                cycle 6,706,911.33
    Compute (SM) Throughput             %         0.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,190
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 64 threads per block and 64 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808234 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 64 blocks, 64 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808234
[808234] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (64, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.82
    gpu__time_duration.avg                                    msecond         9.94
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        29.57
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   10,880,847
    Memory Throughput                   %         2.82
    DRAM Throughput                     %         1.82
    Duration                      msecond         9.94
    L1/TEX Cache Throughput             %         4.77
    L2 Cache Throughput                 %         2.43
    SM Active Cycles                cycle 6,441,048.81
    Compute (SM) Throughput             %         3.24
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,382
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 64 threads per block and 256 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808304 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 256 blocks, 64 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808304
[808304] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (256, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         6.09
    gpu__time_duration.avg                                    msecond         2.99
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        94.83
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.20
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    3,250,579
    Memory Throughput                   %         9.55
    DRAM Throughput                     %         6.09
    Duration                      msecond         2.99
    L1/TEX Cache Throughput             %         9.41
    L2 Cache Throughput                 %         8.27
    SM Active Cycles                cycle 3,300,813.10
    Compute (SM) Throughput             %        10.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          16,384
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         7.41
    Achieved Active Warps Per SM           warp         4.74
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 92.59%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (7.4%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,726,150
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 64 threads per block and 1024 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808350 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1024 blocks, 64 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808350
[808350] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1024, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        18.80
    gpu__time_duration.avg                                    usecond       967.97
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        97.77
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    1,055,265
    Memory Throughput                   %        30.68
    DRAM Throughput                     %        18.80
    Duration                      usecond       967.97
    L1/TEX Cache Throughput             %        31.22
    L2 Cache Throughput                 %        25.09
    SM Active Cycles                cycle 1,036,888.55
    Compute (SM) Throughput             %        33.38
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          65,536
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        29.07
    Achieved Active Warps Per SM           warp        18.60
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 70.93%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (29.1%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,729,222
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 64 threads per block and 4096 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808396 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4096 blocks, 64 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808396
[808396] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4096, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        34.42
    gpu__time_duration.avg                                    usecond       564.64
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        97.90
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      616,433
    Memory Throughput                   %        52.92
    DRAM Throughput                     %        34.42
    Duration                      usecond       564.64
    L1/TEX Cache Throughput             %        53.91
    L2 Cache Throughput                 %        42.72
    SM Active Cycles                cycle   604,984.94
    Compute (SM) Throughput             %        57.18
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         262,144
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 50%
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 639 thread blocks.
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for
          up to 50.0% of the total kernel runtime with a lower occupancy of 29.7%. Try launching a grid with no
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for
          a grid. See the Hardware Model
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more
          details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        70.32
    Achieved Active Warps Per SM           warp        45.01
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 29.68%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (70.3%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,741,510
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 128 threads per block and 1 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808441 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1 blocks, 128 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808441
[808441] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.07
    gpu__time_duration.avg                                    msecond       253.13
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.93
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle  277,908,163
    Memory Throughput                   %         0.11
    DRAM Throughput                     %         0.07
    Duration                      msecond       253.13
    L1/TEX Cache Throughput             %        11.75
    L2 Cache Throughput                 %         0.07
    SM Active Cycles                cycle 2,569,933.51
    Compute (SM) Throughput             %         0.13
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             128
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.25
    Achieved Active Warps Per SM           warp         4.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.75%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,134
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 128 threads per block and 4 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808877 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4 blocks, 128 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808877
[808877] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.21
    gpu__time_duration.avg                                    msecond        84.59
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.67
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   92,684,589
    Memory Throughput                   %         0.35
    DRAM Throughput                     %         0.21
    Duration                      msecond        84.59
    L1/TEX Cache Throughput             %         9.52
    L2 Cache Throughput                 %         0.25
    SM Active Cycles                cycle 3,437,108.02
    Compute (SM) Throughput             %         0.38
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             512
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.25
    Achieved Active Warps Per SM           warp         4.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.75%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,158
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 128 threads per block and 16 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808941 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 16 blocks, 128 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808941
[808941] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.87
    gpu__time_duration.avg                                    msecond        20.68
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        14.57
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   22,702,832
    Memory Throughput                   %         1.42
    DRAM Throughput                     %         0.87
    Duration                      msecond        20.68
    L1/TEX Cache Throughput             %         9.60
    L2 Cache Throughput                 %         1.12
    SM Active Cycles                cycle 3,358,212.44
    Compute (SM) Throughput             %         1.55
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,048
    Waves Per SM                                                0.01
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.25
    Achieved Active Warps Per SM           warp         4.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.75%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,254
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 128 threads per block and 64 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 808986 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 64 blocks, 128 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 808986
[808986] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         3.49
    gpu__time_duration.avg                                    msecond         5.18
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        59.25
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    5,677,622
    Memory Throughput                   %         5.43
    DRAM Throughput                     %         3.49
    Duration                      msecond         5.18
    L1/TEX Cache Throughput             %         9.19
    L2 Cache Throughput                 %         4.68
    SM Active Cycles                cycle 3,357,416.09
    Compute (SM) Throughput             %         6.20
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.04
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.25
    Achieved Active Warps Per SM           warp         4.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.75%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,638
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 128 threads per block and 256 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809031 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 256 blocks, 128 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809031
[809031] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (256, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        10.83
    gpu__time_duration.avg                                    msecond         1.67
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        99.01
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    1,829,110
    Memory Throughput                   %        17.36
    DRAM Throughput                     %        10.83
    Duration                      msecond         1.67
    L1/TEX Cache Throughput             %        17.50
    L2 Cache Throughput                 %        14.47
    SM Active Cycles                cycle 1,814,668.69
    Compute (SM) Throughput             %        19.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          32,768
    Waves Per SM                                                0.15
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        14.79
    Achieved Active Warps Per SM           warp         9.46
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 85.21%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (14.8%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,727,174
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 128 threads per block and 1024 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809098 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1024 blocks, 128 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809098
[809098] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1024, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        30.85
    gpu__time_duration.avg                                    usecond       607.33
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        97.46
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      663,893
    Memory Throughput                   %        49.62
    DRAM Throughput                     %        30.85
    Duration                      usecond       607.33
    L1/TEX Cache Throughput             %        50.76
    L2 Cache Throughput                 %        39.04
    SM Active Cycles                cycle   648,951.42
    Compute (SM) Throughput             %        53.08
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         131,072
    Waves Per SM                                                0.59
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        55.03
    Achieved Active Warps Per SM           warp        35.22
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 44.97%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (55.0%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,733,318
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 128 threads per block and 4096 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809144 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4096 blocks, 128 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809144
[809144] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        39.25
    gpu__time_duration.avg                                    usecond       478.98
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        98.33
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      524,281
    Memory Throughput                   %        63.27
    DRAM Throughput                     %        39.25
    Duration                      usecond       478.98
    L1/TEX Cache Throughput             %        64.27
    L2 Cache Throughput                 %        47.78
    SM Active Cycles                cycle   516,066.19
    Compute (SM) Throughput             %        67.28
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced.
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         524,288
    Waves Per SM                                                2.37
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        85.00
    Achieved Active Warps Per SM           warp        54.40
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 15%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (85.0%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,757,894
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 256 threads per block and 1 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809189 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1 blocks, 256 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809189
[809189] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.11
    gpu__time_duration.avg                                    msecond       170.92
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.93
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle  186,377,596
    Memory Throughput                   %         0.18
    DRAM Throughput                     %         0.11
    Duration                      msecond       170.92
    L1/TEX Cache Throughput             %        19.01
    L2 Cache Throughput                 %         0.10
    SM Active Cycles                cycle 1,758,995.58
    Compute (SM) Throughput             %         0.19
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             256
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.50
    Achieved Active Warps Per SM           warp         8.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.5%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (12.5%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,142
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 256 threads per block and 4 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809278 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4 blocks, 256 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809278
[809278] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.41
    gpu__time_duration.avg                                    msecond        43.86
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.63
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.23
    SM Frequency            cycle/nsecond         1.11
    Elapsed Cycles                  cycle   48,658,794
    Memory Throughput                   %         0.68
    DRAM Throughput                     %         0.41
    Duration                      msecond        43.86
    L1/TEX Cache Throughput             %        18.34
    L2 Cache Throughput                 %         0.43
    SM Active Cycles                cycle 1,804,248.56
    Compute (SM) Throughput             %         0.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.50
    Achieved Active Warps Per SM           warp         8.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.5%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (12.5%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,190
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 256 threads per block and 16 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809345 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 16 blocks, 256 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809345
[809345] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (16, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.55
    gpu__time_duration.avg                                    msecond        11.75
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        14.83
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   12,774,184
    Memory Throughput                   %         2.61
    DRAM Throughput                     %         1.55
    Duration                      msecond        11.75
    L1/TEX Cache Throughput             %        17.63
    L2 Cache Throughput                 %         2.04
    SM Active Cycles                cycle 1,889,382.04
    Compute (SM) Throughput             %         2.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.50
    Achieved Active Warps Per SM           warp         8.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.5%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (12.5%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,382
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 256 threads per block and 64 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809390 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 64 blocks, 256 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809390
[809390] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (64, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         5.69
    gpu__time_duration.avg                                    msecond         3.19
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        59.09
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    3,477,695
    Memory Throughput                   %         9.39
    DRAM Throughput                     %         5.69
    Duration                      msecond         3.19
    L1/TEX Cache Throughput             %        15.85
    L2 Cache Throughput                 %         7.31
    SM Active Cycles                cycle 2,059,888.22
    Compute (SM) Throughput             %        10.13
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          16,384
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.49
    Achieved Active Warps Per SM           warp         7.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.51%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (12.5%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,726,150
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 256 threads per block and 256 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809435 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 256 blocks, 256 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809435
[809435] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (256, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        18.79
    gpu__time_duration.avg                                    usecond       968.32
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        97.79
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    1,053,425
    Memory Throughput                   %        31.44
    DRAM Throughput                     %        18.79
    Duration                      usecond       968.32
    L1/TEX Cache Throughput             %        32.10
    L2 Cache Throughput                 %        23.65
    SM Active Cycles                cycle 1,031,934.99
    Compute (SM) Throughput             %        33.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          65,536
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        29.20
    Achieved Active Warps Per SM           warp        18.69
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 70.8%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (29.2%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,729,222
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 256 threads per block and 1024 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809481 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1024 blocks, 256 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809481
[809481] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1024, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        35.40
    gpu__time_duration.avg                                    usecond       574.30
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        96.18
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      626,582
    Memory Throughput                   %        53.74
    DRAM Throughput                     %        35.40
    Duration                      usecond       574.30
    L1/TEX Cache Throughput             %        55.69
    L2 Cache Throughput                 %        38.74
    SM Active Cycles                cycle   604,463.74
    Compute (SM) Throughput             %        56.26
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         262,144
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 50%
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 159 thread blocks.
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for
          up to 50.0% of the total kernel runtime with a lower occupancy of 28.8%. Try launching a grid with no
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for
          a grid. See the Hardware Model
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more
          details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        71.16
    Achieved Active Warps Per SM           warp        45.55
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 28.84%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (71.2%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,741,510
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 256 threads per block and 4096 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809549 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4096 blocks, 256 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809549
[809549] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4096, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        40.20
    gpu__time_duration.avg                                    usecond       457.38
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        98.32
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      498,244
    Memory Throughput                   %        67.48
    DRAM Throughput                     %        40.20
    Duration                      usecond       457.38
    L1/TEX Cache Throughput             %        68.46
    L2 Cache Throughput                 %        48.12
    SM Active Cycles                cycle   490,967.76
    Compute (SM) Throughput             %        70.91
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced.
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                                4.74
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.48
    Achieved Active Warps Per SM           warp        58.55
    ------------------------------- ----------- ------------

    INF   This kernel's theoretical occupancy is not impacted by any block limit.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,790,662
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 512 threads per block and 1 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809594 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1 blocks, 512 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809594
[809594] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.17
    gpu__time_duration.avg                                    msecond       102.32
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.91
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.24
    SM Frequency            cycle/nsecond         1.11
    Elapsed Cycles                  cycle  113,949,164
    Memory Throughput                   %         0.30
    DRAM Throughput                     %         0.17
    Duration                      msecond       102.32
    L1/TEX Cache Throughput             %        32.76
    L2 Cache Throughput                 %         0.17
    SM Active Cycles                cycle 1,052,618.76
    Compute (SM) Throughput             %         0.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             512
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.98
    Achieved Active Warps Per SM           warp        15.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.02%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (25.0%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,158
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 512 threads per block and 4 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809663 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4 blocks, 512 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809663
[809663] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.71
    gpu__time_duration.avg                                    msecond        25.59
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.71
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   27,974,979
    Memory Throughput                   %         1.23
    DRAM Throughput                     %         0.71
    Duration                      msecond        25.59
    L1/TEX Cache Throughput             %        33.19
    L2 Cache Throughput                 %         1.05
    SM Active Cycles                cycle 1,036,760.82
    Compute (SM) Throughput             %         1.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,048
    Waves Per SM                                                0.01
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.99
    Achieved Active Warps Per SM           warp        15.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.01%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (25.0%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,254
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 512 threads per block and 16 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809733 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 16 blocks, 512 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809733
[809733] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (16, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         2.64
    gpu__time_duration.avg                                    msecond         6.87
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        14.75
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    7,517,345
    Memory Throughput                   %         4.46
    DRAM Throughput                     %         2.64
    Duration                      msecond         6.87
    L1/TEX Cache Throughput             %        30.19
    L2 Cache Throughput                 %         3.74
    SM Active Cycles                cycle 1,110,315.91
    Compute (SM) Throughput             %         4.68
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.04
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp        15.87
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.2%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (24.8%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,638
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 512 threads per block and 64 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809778 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 64 blocks, 512 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809778
[809778] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (64, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        10.10
    gpu__time_duration.avg                                    msecond         1.79
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        58.91
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    1,955,067
    Memory Throughput                   %        17.16
    DRAM Throughput                     %        10.10
    Duration                      msecond         1.79
    L1/TEX Cache Throughput             %        29.11
    L2 Cache Throughput                 %        11.63
    SM Active Cycles                cycle 1,152,320.60
    Compute (SM) Throughput             %        18.01
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          32,768
    Waves Per SM                                                0.15
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp        15.86
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.21%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (24.8%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,727,174
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 512 threads per block and 256 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809823 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 256 blocks, 512 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809823
[809823] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (256, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        29.15
    gpu__time_duration.avg                                    usecond       659.46
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        91.55
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle      722,843
    Memory Throughput                   %        46.73
    DRAM Throughput                     %        29.15
    Duration                      usecond       659.46
    L1/TEX Cache Throughput             %        50.92
    L2 Cache Throughput                 %        31.24
    SM Active Cycles                cycle   663,306.01
    Compute (SM) Throughput             %        48.75
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         131,072
    Waves Per SM                                                0.59
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        55.99
    Achieved Active Warps Per SM           warp        35.83
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 44.01%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (56.0%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,733,318
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 512 threads per block and 1024 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809868 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1024 blocks, 512 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809868
[809868] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1024, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        38.32
    gpu__time_duration.avg                                    usecond       502.53
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        95.68
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      550,086
    Memory Throughput                   %        61.63
    DRAM Throughput                     %        38.32
    Duration                      usecond       502.53
    L1/TEX Cache Throughput             %        64.35
    L2 Cache Throughput                 %        42.16
    SM Active Cycles                cycle   526,718.79
    Compute (SM) Throughput             %        64.14
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced.
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         524,288
    Waves Per SM                                                2.37
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        84.87
    Achieved Active Warps Per SM           warp        54.32
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 15.13%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (84.9%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,757,894
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 512 threads per block and 4096 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809932 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4096 blocks, 512 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809932
[809932] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4096, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        39.45
    gpu__time_duration.avg                                    usecond       459.49
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        98.25
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      502,412
    Memory Throughput                   %        67.03
    DRAM Throughput                     %        39.45
    Duration                      usecond       459.49
    L1/TEX Cache Throughput             %        68.12
    L2 Cache Throughput                 %        47.35
    SM Active Cycles                cycle   494,210.78
    Compute (SM) Throughput             %        70.52
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced.
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       2,097,152
    Waves Per SM                                                9.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.66
    Achieved Active Warps Per SM           warp        59.30
    ------------------------------- ----------- ------------

    INF   This kernel's theoretical occupancy is not impacted by any block limit.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,856,198
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 1024 threads per block and 1 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 809977 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1 blocks, 1024 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 809977
[809977] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.31
    gpu__time_duration.avg                                    msecond        58.64
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.93
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   64,269,211
    Memory Throughput                   %         0.55
    DRAM Throughput                     %         0.31
    Duration                      msecond        58.64
    L1/TEX Cache Throughput             %        59.06
    L2 Cache Throughput                 %         0.30
    SM Active Cycles                cycle   594,755.41
    Compute (SM) Throughput             %         0.55
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        49.93
    Achieved Active Warps Per SM           warp        31.96
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 50.07%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (49.9%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,190
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 1024 threads per block and 4 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 810044 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4 blocks, 1024 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 810044
[810044] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.15
    gpu__time_duration.avg                                    msecond        15.77
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.70
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   17,241,096
    Memory Throughput                   %         1.93
    DRAM Throughput                     %         1.15
    Duration                      msecond        15.77
    L1/TEX Cache Throughput             %        52.13
    L2 Cache Throughput                 %         1.63
    SM Active Cycles                cycle   638,239.06
    Compute (SM) Throughput             %         2.04
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        48.83
    Achieved Active Warps Per SM           warp        31.25
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 51.17%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (48.8%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,725,382
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 1024 threads per block and 16 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 810089 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 16 blocks, 1024 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 810089
[810089] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (16, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         4.44
    gpu__time_duration.avg                                    msecond         4.07
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        14.74
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    4,462,165
    Memory Throughput                   %         7.55
    DRAM Throughput                     %         4.44
    Duration                      msecond         4.07
    L1/TEX Cache Throughput             %        51.18
    L2 Cache Throughput                 %         5.73
    SM Active Cycles                cycle   657,806.81
    Compute (SM) Throughput             %         7.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          16,384
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        48.69
    Achieved Active Warps Per SM           warp        31.16
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 51.31%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (48.7%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,726,150
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 1024 threads per block and 64 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 810134 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 64 blocks, 1024 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 810134
[810134] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (64, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        16.37
    gpu__time_duration.avg                                    msecond         1.10
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        58.47
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    1,204,489
    Memory Throughput                   %        28.16
    DRAM Throughput                     %        16.37
    Duration                      msecond         1.10
    L1/TEX Cache Throughput             %        48.02
    L2 Cache Throughput                 %        17.28
    SM Active Cycles                cycle   706,128.93
    Compute (SM) Throughput             %        29.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full
          waves across all SMs. Look at Launch Statistics for more details.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          65,536
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel
          concurrently with other workloads, consider reducing the block size to have at least one block per
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)
          description for more details on launch configurations.

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        48.57
    Achieved Active Warps Per SM           warp        31.09
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 51.43%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (48.6%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,729,222
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 1024 threads per block and 256 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 810201 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 256 blocks, 1024 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 810201
[810201] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (256, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        32.20
    gpu__time_duration.avg                                    usecond       644.35
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        76.49
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      702,970
    Memory Throughput                   %        48.46
    DRAM Throughput                     %        32.20
    Duration                      usecond       644.35
    L1/TEX Cache Throughput             %        63.15
    L2 Cache Throughput                 %        32.14
    SM Active Cycles                cycle   539,373.28
    Compute (SM) Throughput             %        50.15
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         262,144
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        84.27
    Achieved Active Warps Per SM           warp        53.93
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 15.73%
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated
          theoretical (100.0%) and measured achieved occupancy (84.3%) can be the result of warp scheduling overheads
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on
          optimizing occupancy.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,741,510
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 1024 threads per block and 1024 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 810248 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 1024 blocks, 1024 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 810248
[810248] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (1024, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        38.26
    gpu__time_duration.avg                                    usecond       494.21
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        94.40
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      540,941
    Memory Throughput                   %        62.70
    DRAM Throughput                     %        38.26
    Duration                      usecond       494.21
    L1/TEX Cache Throughput             %        66.30
    L2 Cache Throughput                 %        43.90
    SM Active Cycles                cycle   511,455.94
    Compute (SM) Throughput             %        65.31
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced.
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                                4.74
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.05
    Achieved Active Warps Per SM           warp        58.27
    ------------------------------- ----------- ------------

    INF   This kernel's theoretical occupancy is not impacted by any block limit.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,790,662
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.

Running with 1024 threads per block and 4096 blocks
 Read data from the file ../data/zebra-gray-int8-4x
==PROF== Connected to process 810293 (/pscratch/sd/s/satvik/CSC-746/cp5/build/sobel_gpu)
 GPU configuration: 4096 blocks, 1024 threads per block
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 Wrote the output file ../data/processed-raw-int8-4x-cpu.dat
==PROF== Disconnected from process 810293
[810293] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(float *, float *, int, int, int, float *, float *) (4096, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %        37.44
    gpu__time_duration.avg                                    usecond       482.88
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        98.26
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle      528,256
    Memory Throughput                   %        63.64
    DRAM Throughput                     %        37.44
    Duration                      usecond       482.88
    L1/TEX Cache Throughput             %        64.75
    L2 Cache Throughput                 %        45.40
    SM Active Cycles                cycle   519,102.65
    Compute (SM) Throughput             %        67.44
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced.
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       4,194,304
    Waves Per SM                                               18.96
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.41
    Achieved Active Warps Per SM           warp        58.50
    ------------------------------- ----------- ------------

    INF   This kernel's theoretical occupancy is not impacted by any block limit.

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.04
    Branch Instructions              inst    5,987,270
    Branch Efficiency                   %        99.96
    Avg. Divergent Branches                       3.07
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%
          This kernel has uncoalesced global accesses resulting in a total of 6853584 excessive sectors (9% of the
          total 73180108 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source
          locations. The CUDA Programming Guide
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional
          information on reducing uncoalesced device memory accesses.